{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31969215-2a90-4d8b-ac36-646a7ae13744",
   "metadata": {
    "id": "31969215-2a90-4d8b-ac36-646a7ae13744"
   },
   "source": [
    "# Lab | Data Aggregation and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f08a52-bec0-439b-99cc-11d3809d8b5d",
   "metadata": {
    "id": "a8f08a52-bec0-439b-99cc-11d3809d8b5d"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company. We will use the dataset called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by first performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bd78fb-850c-49b3-8bca-28aa447ca948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unnamed:_0', 'customer', 'state', 'customer_lifetime_value',\n",
       "       'response', 'coverage', 'education', 'effective_to_date',\n",
       "       'employmentstatus', 'gender', 'income', 'location_code',\n",
       "       'marital_status', 'monthly_premium_auto', 'months_since_last_claim',\n",
       "       'months_since_policy_inception', 'number_of_open_complaints',\n",
       "       'number_of_policies', 'policy_type', 'policy', 'renew_offer_type',\n",
       "       'sales_channel', 'total_claim_amount', 'vehicle_class', 'vehicle_size',\n",
       "       'vehicle_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821a522f-b4d0-45f7-beae-29273ca2c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 0\n",
      "customer: \n",
      " * Nr. of unique vals: 9134 \n",
      " * unique vals: ['DK49336' 'KX64629' 'LZ68649' ... 'KX53892' 'TL39050' 'WA60547']\n",
      "\n",
      "\n",
      "state: \n",
      " * Nr. of unique vals: 5 \n",
      " * unique vals: ['Arizona' 'California' 'Washington' 'Oregon' nan 'Nevada']\n",
      "\n",
      "\n",
      "response: \n",
      " * Nr. of unique vals: 2 \n",
      " * unique vals: ['No' 'Yes' nan]\n",
      "\n",
      "\n",
      "coverage: \n",
      " * Nr. of unique vals: 3 \n",
      " * unique vals: ['Basic' 'Extended' 'Premium']\n",
      "\n",
      "\n",
      "education: \n",
      " * Nr. of unique vals: 5 \n",
      " * unique vals: ['College' 'Bachelor' 'High School or Below' 'Doctor' 'Master']\n",
      "\n",
      "\n",
      "effective_to_date: \n",
      " * Nr. of unique vals: 59 \n",
      " * unique vals: ['2/18/11' '1/18/11' '2/10/11' '1/11/11' '1/17/11' '2/14/11' '2/24/11'\n",
      " '1/19/11' '1/4/11' '1/2/11' '2/7/11' '1/31/11' '1/26/11' '2/28/11'\n",
      " '1/16/11' '2/26/11' '2/23/11' '1/15/11' '2/2/11' '2/15/11' '1/24/11'\n",
      " '2/21/11' '2/22/11' '1/7/11' '1/28/11' '2/8/11' '2/12/11' '2/20/11'\n",
      " '1/5/11' '2/19/11' '1/3/11' '2/3/11' '1/22/11' '1/23/11' '2/5/11'\n",
      " '2/13/11' '1/25/11' '2/16/11' '2/1/11' '1/27/11' '1/12/11' '1/20/11'\n",
      " '2/6/11' '2/11/11' '1/21/11' '1/29/11' '1/9/11' '2/9/11' '2/27/11'\n",
      " '1/1/11' '2/17/11' '2/25/11' '1/13/11' '1/6/11' '2/4/11' '1/14/11'\n",
      " '1/10/11' '1/8/11' '1/30/11']\n",
      "\n",
      "\n",
      "employmentstatus: \n",
      " * Nr. of unique vals: 5 \n",
      " * unique vals: ['Employed' 'Unemployed' 'Medical Leave' 'Disabled' 'Retired']\n",
      "\n",
      "\n",
      "gender: \n",
      " * Nr. of unique vals: 2 \n",
      " * unique vals: ['M' 'F']\n",
      "\n",
      "\n",
      "location_code: \n",
      " * Nr. of unique vals: 3 \n",
      " * unique vals: ['Suburban' 'Urban' 'Rural']\n",
      "\n",
      "\n",
      "marital_status: \n",
      " * Nr. of unique vals: 3 \n",
      " * unique vals: ['Married' 'Single' 'Divorced']\n",
      "\n",
      "\n",
      "policy_type: \n",
      " * Nr. of unique vals: 3 \n",
      " * unique vals: ['Corporate Auto' 'Personal Auto' 'Special Auto']\n",
      "\n",
      "\n",
      "policy: \n",
      " * Nr. of unique vals: 9 \n",
      " * unique vals: ['Corporate L3' 'Personal L3' 'Personal L2' 'Corporate L2' 'Personal L1'\n",
      " 'Special L1' 'Corporate L1' 'Special L3' 'Special L2']\n",
      "\n",
      "\n",
      "renew_offer_type: \n",
      " * Nr. of unique vals: 4 \n",
      " * unique vals: ['Offer3' 'Offer4' 'Offer2' 'Offer1']\n",
      "\n",
      "\n",
      "sales_channel: \n",
      " * Nr. of unique vals: 4 \n",
      " * unique vals: ['Agent' 'Call Center' 'Branch' 'Web']\n",
      "\n",
      "\n",
      "vehicle_class: \n",
      " * Nr. of unique vals: 6 \n",
      " * unique vals: ['Four-Door Car' 'SUV' 'Two-Door Car' 'Sports Car' 'Luxury Car'\n",
      " 'Luxury SUV' nan]\n",
      "\n",
      "\n",
      "vehicle_size: \n",
      " * Nr. of unique vals: 3 \n",
      " * unique vals: ['Medsize' 'Small' 'Large' nan]\n",
      "\n",
      "\n",
      "vehicle_type: \n",
      " * Nr. of unique vals: 1 \n",
      " * unique vals: [nan 'A']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleaning\n",
    "# check for rows with all NaN\n",
    "initial_shape = df.shape\n",
    "df = df.dropna(how='all')\n",
    "final_shape = df.shape\n",
    "\n",
    "print(f\"Number of rows dropped: {initial_shape[0] - final_shape[0]}\")\n",
    "\n",
    "# check for dublicates\n",
    "df.duplicated().any()\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# check if recoding needs to be done\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        print(f'{col}:', '\\n', f'* Nr. of unique vals: {(df[col].nunique())}', '\\n', f'* unique vals: {df[col].unique()}')\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98ddc5-b041-4c94-ada1-4dfee5c98e50",
   "metadata": {
    "id": "9c98ddc5-b041-4c94-ada1-4dfee5c98e50"
   },
   "source": [
    "1. Create a new DataFrame that only includes customers who have a total_claim_amount greater than $1,000 and have a response of \"Yes\" to the last marketing campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac40bd48-a035-432f-aef6-1df74a418942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df_new = df[(df['total_claim_amount'] >1000) & (df['response'] == 'yes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be383e-5165-436e-80c8-57d4c757c8c3",
   "metadata": {
    "id": "b9be383e-5165-436e-80c8-57d4c757c8c3"
   },
   "source": [
    "2. Using the original Dataframe, analyze the average total_claim_amount by each policy type and gender for customers who have responded \"Yes\" to the last marketing campaign. Write your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd98072-1cd5-460c-9da4-4fff557be718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gender</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Corporate Auto</th>\n",
       "      <td>433.74</td>\n",
       "      <td>408.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Auto</th>\n",
       "      <td>452.97</td>\n",
       "      <td>457.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Special Auto</th>\n",
       "      <td>453.28</td>\n",
       "      <td>429.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gender               F       M\n",
       "policy_type                   \n",
       "Corporate Auto  433.74  408.58\n",
       "Personal Auto   452.97  457.01\n",
       "Special Auto    453.28  429.53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "pivot_df = df[df['response'] == 'Yes'].pivot_table(\n",
    "    index='policy_type', \n",
    "    columns='gender', \n",
    "    values='total_claim_amount', \n",
    "    aggfunc='mean').round(2)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f4ac-53c5-4193-a3c0-8699b87196f0",
   "metadata": {
    "id": "7050f4ac-53c5-4193-a3c0-8699b87196f0"
   },
   "source": [
    "3. Analyze the total number of customers who have policies in each state, and then filter the results to only include states where there are more than 500 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5d0e2ed-9b5e-49c0-81af-61070447c3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Washington     888\n",
       "Nevada         993\n",
       "Arizona       1937\n",
       "Oregon        2909\n",
       "California    3552\n",
       "Name: customer, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "# Assuming 'data' is your DataFrame\n",
    "stategrouped = df.groupby('state')['customer'].count()\n",
    "stategrouped_filtered = stategrouped[stategrouped > 500]\n",
    "stategrouped_filtered.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a4443-a1a7-4bbf-b78e-9ccdf9895e0d",
   "metadata": {
    "id": "b60a4443-a1a7-4bbf-b78e-9ccdf9895e0d"
   },
   "source": [
    "4. Find the maximum, minimum, and median customer lifetime value by education level and gender. Write your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a575f84a-4899-4fa0-a4af-04f17092a68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">F</th>\n",
       "      <th>Bachelor</th>\n",
       "      <td>73225.96</td>\n",
       "      <td>5640.51</td>\n",
       "      <td>1904.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>College</th>\n",
       "      <td>61850.19</td>\n",
       "      <td>5623.61</td>\n",
       "      <td>1898.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>44856.11</td>\n",
       "      <td>5332.46</td>\n",
       "      <td>2395.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High School or Below</th>\n",
       "      <td>55277.45</td>\n",
       "      <td>6039.55</td>\n",
       "      <td>2144.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>51016.07</td>\n",
       "      <td>5729.86</td>\n",
       "      <td>2417.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">M</th>\n",
       "      <th>Bachelor</th>\n",
       "      <td>67907.27</td>\n",
       "      <td>5548.03</td>\n",
       "      <td>1898.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>College</th>\n",
       "      <td>61134.68</td>\n",
       "      <td>6005.85</td>\n",
       "      <td>1918.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>32677.34</td>\n",
       "      <td>5577.67</td>\n",
       "      <td>2267.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High School or Below</th>\n",
       "      <td>83325.38</td>\n",
       "      <td>6286.73</td>\n",
       "      <td>1940.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>50568.26</td>\n",
       "      <td>5579.10</td>\n",
       "      <td>2272.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  max   median      min\n",
       "gender education                                       \n",
       "F      Bachelor              73225.96  5640.51  1904.00\n",
       "       College               61850.19  5623.61  1898.68\n",
       "       Doctor                44856.11  5332.46  2395.57\n",
       "       High School or Below  55277.45  6039.55  2144.92\n",
       "       Master                51016.07  5729.86  2417.78\n",
       "M      Bachelor              67907.27  5548.03  1898.01\n",
       "       College               61134.68  6005.85  1918.12\n",
       "       Doctor                32677.34  5577.67  2267.60\n",
       "       High School or Below  83325.38  6286.73  1940.98\n",
       "       Master                50568.26  5579.10  2272.31"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "grouped = df.groupby(['gender', 'education'])['customer_lifetime_value'].agg(['max', 'median', 'min']).round(2)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42999f9-311f-481e-ae63-40a5577072c5",
   "metadata": {
    "id": "b42999f9-311f-481e-ae63-40a5577072c5"
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff02c5-6584-4f21-a358-b918697c6432",
   "metadata": {
    "id": "81ff02c5-6584-4f21-a358-b918697c6432"
   },
   "source": [
    "5. The marketing team wants to analyze the number of policies sold by state and month. Present the data in a table where the months are arranged as columns and the states are arranged as rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aec097-c633-4017-a125-e77a97259cda",
   "metadata": {
    "id": "b6aec097-c633-4017-a125-e77a97259cda"
   },
   "source": [
    "6.  Display a new DataFrame that contains the number of policies sold by month, by state, for the top 3 states with the highest number of policies sold.\n",
    "\n",
    "*Hint:*\n",
    "- *To accomplish this, you will first need to group the data by state and month, then count the number of policies sold for each group. Afterwards, you will need to sort the data by the count of policies sold in descending order.*\n",
    "- *Next, you will select the top 3 states with the highest number of policies sold.*\n",
    "- *Finally, you will create a new DataFrame that contains the number of policies sold by month for each of the top 3 states.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba975b8a-a2cf-4fbf-9f59-ebc381767009",
   "metadata": {
    "id": "ba975b8a-a2cf-4fbf-9f59-ebc381767009"
   },
   "source": [
    "7. The marketing team wants to analyze the effect of different marketing channels on the customer response rate.\n",
    "\n",
    "Hint: You can use melt to unpivot the data and create a table that shows the customer response rate (those who responded \"Yes\") by marketing channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4378d94-48fb-4850-a802-b1bc8f427b2d",
   "metadata": {
    "id": "e4378d94-48fb-4850-a802-b1bc8f427b2d"
   },
   "source": [
    "External Resources for Data Filtering: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449513f4-0459-46a0-a18d-9398d974c9ad",
   "metadata": {
    "id": "449513f4-0459-46a0-a18d-9398d974c9ad"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
