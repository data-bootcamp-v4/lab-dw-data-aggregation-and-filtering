{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31969215-2a90-4d8b-ac36-646a7ae13744",
   "metadata": {
    "id": "31969215-2a90-4d8b-ac36-646a7ae13744"
   },
   "source": [
    "# Lab | Data Aggregation and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f08a52-bec0-439b-99cc-11d3809d8b5d",
   "metadata": {
    "id": "a8f08a52-bec0-439b-99cc-11d3809d8b5d"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company. We will use the dataset called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by first performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98ddc5-b041-4c94-ada1-4dfee5c98e50",
   "metadata": {
    "id": "9c98ddc5-b041-4c94-ada1-4dfee5c98e50"
   },
   "source": [
    "1. Create a new DataFrame that only includes customers who have a total_claim_amount greater than $1,000 and have a response of \"Yes\" to the last marketing campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be383e-5165-436e-80c8-57d4c757c8c3",
   "metadata": {
    "id": "b9be383e-5165-436e-80c8-57d4c757c8c3"
   },
   "source": [
    "2. Using the original Dataframe, analyze the average total_claim_amount by each policy type and gender for customers who have responded \"Yes\" to the last marketing campaign. Write your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f4ac-53c5-4193-a3c0-8699b87196f0",
   "metadata": {
    "id": "7050f4ac-53c5-4193-a3c0-8699b87196f0"
   },
   "source": [
    "3. Analyze the total number of customers who have policies in each state, and then filter the results to only include states where there are more than 500 customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a4443-a1a7-4bbf-b78e-9ccdf9895e0d",
   "metadata": {
    "id": "b60a4443-a1a7-4bbf-b78e-9ccdf9895e0d"
   },
   "source": [
    "4. Find the maximum, minimum, and median customer lifetime value by education level and gender. Write your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99b89762-3335-4ec9-8d1a-e58fd8babeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>state</th>\n",
       "      <th>customer_lifetime_value</th>\n",
       "      <th>response</th>\n",
       "      <th>coverage</th>\n",
       "      <th>education</th>\n",
       "      <th>effective_to_date</th>\n",
       "      <th>employmentstatus</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_open_complaints</th>\n",
       "      <th>number_of_policies</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>policy</th>\n",
       "      <th>renew_offer_type</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>vehicle_class</th>\n",
       "      <th>vehicle_size</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>OK31456</td>\n",
       "      <td>California</td>\n",
       "      <td>11009.130490</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1/24/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>51643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L3</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1358.400000</td>\n",
       "      <td>Luxury Car</td>\n",
       "      <td>Medsize</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>YJ16163</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>11009.130490</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1/24/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>51643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Special Auto</td>\n",
       "      <td>Special L3</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1358.400000</td>\n",
       "      <td>Luxury Car</td>\n",
       "      <td>Medsize</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>GW43195</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>25807.063000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>2/13/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>71210</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Branch</td>\n",
       "      <td>1027.200000</td>\n",
       "      <td>Luxury Car</td>\n",
       "      <td>Small</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>IP94270</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>13736.132500</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Master</td>\n",
       "      <td>2/13/11</td>\n",
       "      <td>Disabled</td>\n",
       "      <td>F</td>\n",
       "      <td>16181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Web</td>\n",
       "      <td>1261.319869</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Medsize</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>FJ28407</td>\n",
       "      <td>California</td>\n",
       "      <td>5619.689084</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Premium</td>\n",
       "      <td>High School or Below</td>\n",
       "      <td>1/26/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L1</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Web</td>\n",
       "      <td>1027.000029</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Medsize</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10351</th>\n",
       "      <td>FN44127</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>3508.569533</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>1/5/11</td>\n",
       "      <td>Medical Leave</td>\n",
       "      <td>M</td>\n",
       "      <td>20978</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L2</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Branch</td>\n",
       "      <td>1176.278800</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Small</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>XZ64172</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>10963.957230</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Premium</td>\n",
       "      <td>High School or Below</td>\n",
       "      <td>2/8/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>55687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1324.800000</td>\n",
       "      <td>Luxury SUV</td>\n",
       "      <td>Medsize</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10487</th>\n",
       "      <td>IX60941</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>3508.569533</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>1/5/11</td>\n",
       "      <td>Medical Leave</td>\n",
       "      <td>M</td>\n",
       "      <td>20978</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Branch</td>\n",
       "      <td>1176.278800</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Small</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>QO62792</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>7840.165778</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>1/14/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>58414</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10708</th>\n",
       "      <td>CK39096</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>5619.689084</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Premium</td>\n",
       "      <td>High School or Below</td>\n",
       "      <td>1/26/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Web</td>\n",
       "      <td>1027.000029</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Medsize</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer       state  customer_lifetime_value response  coverage  \\\n",
       "189    OK31456  California             11009.130490      Yes   Premium   \n",
       "236    YJ16163      Oregon             11009.130490      Yes   Premium   \n",
       "419    GW43195      Oregon             25807.063000      Yes  Extended   \n",
       "442    IP94270     Arizona             13736.132500      Yes   Premium   \n",
       "587    FJ28407  California              5619.689084      Yes   Premium   \n",
       "...        ...         ...                      ...      ...       ...   \n",
       "10351  FN44127      Oregon              3508.569533      Yes  Extended   \n",
       "10373  XZ64172      Oregon             10963.957230      Yes   Premium   \n",
       "10487  IX60941      Oregon              3508.569533      Yes  Extended   \n",
       "10565  QO62792      Oregon              7840.165778      Yes  Extended   \n",
       "10708  CK39096      Oregon              5619.689084      Yes   Premium   \n",
       "\n",
       "                  education effective_to_date employmentstatus gender  income  \\\n",
       "189                Bachelor           1/24/11         Employed      F   51643   \n",
       "236                Bachelor           1/24/11         Employed      F   51643   \n",
       "419                 College           2/13/11         Employed      F   71210   \n",
       "442                  Master           2/13/11         Disabled      F   16181   \n",
       "587    High School or Below           1/26/11       Unemployed      M       0   \n",
       "...                     ...               ...              ...    ...     ...   \n",
       "10351               College            1/5/11    Medical Leave      M   20978   \n",
       "10373  High School or Below            2/8/11         Employed      M   55687   \n",
       "10487               College            1/5/11    Medical Leave      M   20978   \n",
       "10565               College           1/14/11         Employed      M   58414   \n",
       "10708  High School or Below           1/26/11       Unemployed      M       0   \n",
       "\n",
       "       ... number_of_open_complaints number_of_policies     policy_type  \\\n",
       "189    ...                       0.0                  1  Corporate Auto   \n",
       "236    ...                       0.0                  1    Special Auto   \n",
       "419    ...                       1.0                  2   Personal Auto   \n",
       "442    ...                       0.0                  8   Personal Auto   \n",
       "587    ...                       0.0                  1   Personal Auto   \n",
       "...    ...                       ...                ...             ...   \n",
       "10351  ...                       1.0                  1   Personal Auto   \n",
       "10373  ...                       0.0                  1  Corporate Auto   \n",
       "10487  ...                       1.0                  1   Personal Auto   \n",
       "10565  ...                       2.0                  1   Personal Auto   \n",
       "10708  ...                       0.0                  1   Personal Auto   \n",
       "\n",
       "             policy  renew_offer_type  sales_channel  total_claim_amount  \\\n",
       "189    Corporate L3            Offer2          Agent         1358.400000   \n",
       "236      Special L3            Offer2          Agent         1358.400000   \n",
       "419     Personal L2            Offer1         Branch         1027.200000   \n",
       "442     Personal L2            Offer1            Web         1261.319869   \n",
       "587     Personal L1            Offer2            Web         1027.000029   \n",
       "...             ...               ...            ...                 ...   \n",
       "10351   Personal L2            Offer2         Branch         1176.278800   \n",
       "10373  Corporate L2            Offer1          Agent         1324.800000   \n",
       "10487   Personal L3            Offer2         Branch         1176.278800   \n",
       "10565   Personal L3            Offer2          Agent         1008.000000   \n",
       "10708   Personal L3            Offer2            Web         1027.000029   \n",
       "\n",
       "       vehicle_class vehicle_size vehicle_type  \n",
       "189       Luxury Car      Medsize          NaN  \n",
       "236       Luxury Car      Medsize            A  \n",
       "419       Luxury Car        Small            A  \n",
       "442              SUV      Medsize            A  \n",
       "587              SUV      Medsize            A  \n",
       "...              ...          ...          ...  \n",
       "10351  Four-Door Car        Small          NaN  \n",
       "10373     Luxury SUV      Medsize          NaN  \n",
       "10487  Four-Door Car        Small          NaN  \n",
       "10565            NaN          NaN          NaN  \n",
       "10708            SUV      Medsize            A  \n",
       "\n",
       "[67 rows x 25 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new DataFrame that only includes customers who have a total_claim_amount greater than $1,000 \n",
    "#and have a response of \"Yes\" to the last marketing campaign.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Replace uppercase labels with lowercase and add underscores\n",
    "df.columns = [col.lower().replace(\" \",\"_\") for col in df.columns]\n",
    "\n",
    "#Create a new DataFrame that only includes customers who have a total_claim_amount greater than $1,000 and\n",
    "#have a response of \"Yes\" to the last marketing campaign.\n",
    "df = df[(df['total_claim_amount'] > 1000) & (df['response'] == 'Yes')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de93fd5b-2ce5-4c1d-880f-e2e0f9a94b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      policy_type gender  total_claim_amount\n",
      "0  Corporate Auto      F         1138.400000\n",
      "1  Corporate Auto      M         1171.150007\n",
      "2   Personal Auto      F         1214.853805\n",
      "3   Personal Auto      M         1137.861443\n",
      "4    Special Auto      F         1358.400000\n",
      "5    Special Auto      M         1017.500015\n"
     ]
    }
   ],
   "source": [
    "#Using the original Dataframe, analyze the average total_claim_amount by each policy type and gender \n",
    "#for customers who have responded \"Yes\" to the last marketing campaign. Write your conclusions.\n",
    "\n",
    "#df = df[df['response'] == 'Yes']\n",
    "df = df.groupby(['policy_type', 'gender'])['total_claim_amount'].mean().reset_index()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4853bebb-b0b2-4f0c-a57a-d15d51c06c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy</th>\n",
       "      <th>state</th>\n",
       "      <th>customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Personal L2</td>\n",
       "      <td>California</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Personal L2</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Personal L3</td>\n",
       "      <td>California</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         policy       state  customer\n",
       "21  Personal L2  California       905\n",
       "23  Personal L2      Oregon       618\n",
       "25  Personal L3     Arizona       742\n",
       "26  Personal L3  California      1250\n",
       "28  Personal L3      Oregon      1157"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyze the total number of customers who have policies in each state, and then filter the results\n",
    "#to only include states where there are more than 500 customers.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Replace uppercase labels with lowercase and add underscores\n",
    "df.columns = [col.lower().replace(\" \",\"_\") for col in df.columns]\n",
    "\n",
    "df = df.groupby(['policy', 'state'])['customer'].count().reset_index()\n",
    "df = df[(df['customer'] > 500)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b9c76f17-eed4-4471-9739-75b2290fcfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education             gender\n",
       "Bachelor              F         73225.95652\n",
       "                      M         67907.27050\n",
       "College               F         61850.18803\n",
       "                      M         61134.68307\n",
       "Doctor                F         44856.11397\n",
       "                      M         32677.34284\n",
       "High School or Below  F         55277.44589\n",
       "                      M         83325.38119\n",
       "Master                F         51016.06704\n",
       "                      M         50568.25912\n",
       "Name: customer_lifetime_value, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum, minimum, and median customer lifetime value by education level and gender.\n",
    "#Write your conclusions.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Replace uppercase labels with lowercase and add underscores\n",
    "df.columns = [col.lower().replace(\" \",\"_\") for col in df.columns]\n",
    "\n",
    "max_customer_lifetime_value = df.groupby(['education', 'gender'])['customer_lifetime_value'].max()\n",
    "max_customer_lifetime_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cf4f7f2f-98aa-4f27-80fe-4bc01d1f2b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education             gender\n",
       "Bachelor              F         1904.000852\n",
       "                      M         1898.007675\n",
       "College               F         1898.683686\n",
       "                      M         1918.119700\n",
       "Doctor                F         2395.570000\n",
       "                      M         2267.604038\n",
       "High School or Below  F         2144.921535\n",
       "                      M         1940.981221\n",
       "Master                F         2417.777032\n",
       "                      M         2272.307310\n",
       "Name: customer_lifetime_value, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_customer_lifetime_value = df.groupby(['education', 'gender'])['customer_lifetime_value'].min()\n",
    "min_customer_lifetime_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c57d7dc3-a99c-4398-bc7d-c25cc996a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education             gender\n",
       "Bachelor              F         5640.505303\n",
       "                      M         5548.031892\n",
       "College               F         5623.611187\n",
       "                      M         6005.847375\n",
       "Doctor                F         5332.462694\n",
       "                      M         5577.669457\n",
       "High School or Below  F         6039.553187\n",
       "                      M         6286.731006\n",
       "Master                F         5729.855012\n",
       "                      M         5579.099207\n",
       "Name: customer_lifetime_value, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_customer_lifetime_value = df.groupby(['education', 'gender'])['customer_lifetime_value'].median()\n",
    "median_customer_lifetime_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42999f9-311f-481e-ae63-40a5577072c5",
   "metadata": {
    "id": "b42999f9-311f-481e-ae63-40a5577072c5"
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff02c5-6584-4f21-a358-b918697c6432",
   "metadata": {
    "id": "81ff02c5-6584-4f21-a358-b918697c6432"
   },
   "source": [
    "5. The marketing team wants to analyze the number of policies sold by state and month. Present the data in a table where the months are arranged as columns and the states are arranged as rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aec097-c633-4017-a125-e77a97259cda",
   "metadata": {
    "id": "b6aec097-c633-4017-a125-e77a97259cda"
   },
   "source": [
    "6.  Display a new DataFrame that contains the number of policies sold by month, by state, for the top 3 states with the highest number of policies sold.\n",
    "\n",
    "*Hint:*\n",
    "- *To accomplish this, you will first need to group the data by state and month, then count the number of policies sold for each group. Afterwards, you will need to sort the data by the count of policies sold in descending order.*\n",
    "- *Next, you will select the top 3 states with the highest number of policies sold.*\n",
    "- *Finally, you will create a new DataFrame that contains the number of policies sold by month for each of the top 3 states.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba975b8a-a2cf-4fbf-9f59-ebc381767009",
   "metadata": {
    "id": "ba975b8a-a2cf-4fbf-9f59-ebc381767009"
   },
   "source": [
    "7. The marketing team wants to analyze the effect of different marketing channels on the customer response rate.\n",
    "\n",
    "Hint: You can use melt to unpivot the data and create a table that shows the customer response rate (those who responded \"Yes\") by marketing channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4378d94-48fb-4850-a802-b1bc8f427b2d",
   "metadata": {
    "id": "e4378d94-48fb-4850-a802-b1bc8f427b2d"
   },
   "source": [
    "External Resources for Data Filtering: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "449513f4-0459-46a0-a18d-9398d974c9ad",
   "metadata": {
    "id": "449513f4-0459-46a0-a18d-9398d974c9ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/43/30gtvzf54299gghzdyc8_l900000gn/T/ipykernel_6093/1513547027.py:12: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df['month'] = pd.date_range(start='2023-01-01', periods=len(df), freq='M').month\n"
     ]
    },
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds timestamp: 2932-02-29 00:00:00 with frequency 'ns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32mtimestamps.pyx:2476\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.replace\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: Overflow occurred in npy_datetimestruct_to_datetime",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [col\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Add a month column\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df), freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmonth\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Grouping and counting the number of policies sold\u001b[39;00m\n\u001b[1;32m     15\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolicy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:1008\u001b[0m, in \u001b[0;36mdate_range\u001b[0;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_none(periods, start, end):\n\u001b[1;32m   1006\u001b[0m     freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1008\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m DatetimeArray\u001b[38;5;241m.\u001b[39m_generate_range(\n\u001b[1;32m   1009\u001b[0m     start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m   1010\u001b[0m     end\u001b[38;5;241m=\u001b[39mend,\n\u001b[1;32m   1011\u001b[0m     periods\u001b[38;5;241m=\u001b[39mperiods,\n\u001b[1;32m   1012\u001b[0m     freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[1;32m   1013\u001b[0m     tz\u001b[38;5;241m=\u001b[39mtz,\n\u001b[1;32m   1014\u001b[0m     normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[1;32m   1015\u001b[0m     inclusive\u001b[38;5;241m=\u001b[39minclusive,\n\u001b[1;32m   1016\u001b[0m     unit\u001b[38;5;241m=\u001b[39munit,\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1018\u001b[0m )\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex\u001b[38;5;241m.\u001b[39m_simple_new(dtarr, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:468\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[0;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     xdr \u001b[38;5;241m=\u001b[39m _generate_range(\n\u001b[1;32m    466\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, periods\u001b[38;5;241m=\u001b[39mperiods, offset\u001b[38;5;241m=\u001b[39mfreq, unit\u001b[38;5;241m=\u001b[39munit\n\u001b[1;32m    467\u001b[0m     )\n\u001b[0;32m--> 468\u001b[0m     i8values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xdr], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    470\u001b[0m endpoint_tz \u001b[38;5;241m=\u001b[39m start\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m end\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m endpoint_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:2780\u001b[0m, in \u001b[0;36m_generate_range\u001b[0;34m(start, end, periods, offset, unit)\u001b[0m\n\u001b[1;32m   2775\u001b[0m     periods \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2778\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__radd__\" of \"BaseOffset\" matches\u001b[39;00m\n\u001b[1;32m   2779\u001b[0m     \u001b[38;5;66;03m# argument type \"None\"\u001b[39;00m\n\u001b[0;32m-> 2780\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m (periods \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m offset  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   2782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2783\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__radd__\" of \"BaseOffset\" matches\u001b[39;00m\n\u001b[1;32m   2784\u001b[0m     \u001b[38;5;66;03m# argument type \"None\"\u001b[39;00m\n\u001b[1;32m   2785\u001b[0m     start \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m (periods \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m offset  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32moffsets.pyx:468\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.BaseOffset.__radd__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:463\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.BaseOffset.__add__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:141\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.apply_wraps.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.MonthOffset._apply\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:5226\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.shift_month\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimestamps.pyx:2479\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.replace\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds timestamp: 2932-02-29 00:00:00 with frequency 'ns'"
     ]
    }
   ],
   "source": [
    "#The marketing team wants to analyze the number of policies sold by state and month.\n",
    "#Present the data in a table where the months are arranged as columns and the states are arranged as rows.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Replace uppercase labels with lowercase and add underscores\n",
    "df.columns = [col.lower().replace(\" \",\"_\") for col in df.columns]\n",
    "\n",
    "# Add a month column\n",
    "df['month'] = pd.date_range(start='2023-01-01', periods=len(df), freq='M').month\n",
    "\n",
    "# Grouping and counting the number of policies sold\n",
    "grouped_df = df.groupby(['state', 'month'])['policy'].count().reset_index()\n",
    "\n",
    "# Pivoting the table\n",
    "pivot_table = grouped_df.pivot_table(index='state', columns='month', values='policy', fill_value=0)\n",
    "\n",
    "# Display the resulting pivot table\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f14b3364-222d-4466-b40c-d7af70ad118c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'month'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [col\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure that the date column is in datetime format\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Replace with your actual date column\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Add a month column based on the date column\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'month'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Replace uppercase labels with lowercase and add underscores\n",
    "df.columns = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "\n",
    "df['month'] = pd.date_range(start='2023-01-01', periods=len(df), freq='M').month\n",
    "\n",
    "# Ensure that the date column is in datetime format\n",
    "df['month'] = pd.to_datetime(df['month'])  # Replace with your actual date column\n",
    "\n",
    "# Add a month column based on the date column\n",
    "df['month'] = df['month'].dt.month\n",
    "\n",
    "# Grouping and counting the number of policies sold\n",
    "grouped_df = df.groupby(['state', 'month'])['policy'].count().reset_index()\n",
    "\n",
    "# Pivoting the table to get states as rows and months as columns\n",
    "pivot_table = grouped_df.pivot_table(index='state', columns='month', values='policy', fill_value=0)\n",
    "\n",
    "# Sort the pivot table for better readability\n",
    "pivot_table = pivot_table.sort_index()\n",
    "\n",
    "# Display the resulting pivot table\n",
    "print(pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a91438-70ca-419d-a713-d3e4024e02de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
